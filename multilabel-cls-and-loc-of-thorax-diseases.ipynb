{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom PIL import Image\nfrom sklearn.metrics import multilabel_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-12-24T05:47:55.564195Z","iopub.execute_input":"2023-12-24T05:47:55.564605Z","iopub.status.idle":"2023-12-24T05:47:57.549420Z","shell.execute_reply.started":"2023-12-24T05:47:55.564563Z","shell.execute_reply":"2023-12-24T05:47:57.548582Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Concatenate\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.applications import VGG16, VGG19, ResNet50, ResNet101","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:20.478585Z","iopub.execute_input":"2023-12-23T17:09:20.479165Z","iopub.status.idle":"2023-12-23T17:09:29.924548Z","shell.execute_reply.started":"2023-12-23T17:09:20.479130Z","shell.execute_reply":"2023-12-23T17:09:29.923477Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"complete_data_info = pd.read_csv(\"/kaggle/input/data/Data_Entry_2017.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:31.660834Z","iopub.execute_input":"2023-12-23T17:09:31.661591Z","iopub.status.idle":"2023-12-23T17:09:32.072543Z","shell.execute_reply.started":"2023-12-23T17:09:31.661554Z","shell.execute_reply":"2023-12-23T17:09:32.071421Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_base_path = \"/kaggle/input/data\"","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:32.861485Z","iopub.execute_input":"2023-12-23T17:09:32.861925Z","iopub.status.idle":"2023-12-23T17:09:32.866556Z","shell.execute_reply.started":"2023-12-23T17:09:32.861888Z","shell.execute_reply":"2023-12-23T17:09:32.865432Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"complete_data_imgs_paths = list()\nimgs_file_names = list()\n\nfor single_img_path in Path(data_base_path).glob(\"images_*/images/*.png\"):\n    \n    complete_data_imgs_paths.append(str(single_img_path))\n    imgs_file_names.append(str(single_img_path.parts[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:33.997611Z","iopub.execute_input":"2023-12-23T17:09:33.998610Z","iopub.status.idle":"2023-12-23T17:09:40.185606Z","shell.execute_reply.started":"2023-12-23T17:09:33.998557Z","shell.execute_reply":"2023-12-23T17:09:40.184325Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"complete_data_path_info = pd.DataFrame(data={\"Image Index\":imgs_file_names,\n                                            \"Image Path\":complete_data_imgs_paths})","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:42.605322Z","iopub.execute_input":"2023-12-23T17:09:42.606657Z","iopub.status.idle":"2023-12-23T17:09:42.634675Z","shell.execute_reply.started":"2023-12-23T17:09:42.606613Z","shell.execute_reply":"2023-12-23T17:09:42.633527Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"complete_data_all_info = complete_data_info.merge(complete_data_path_info,on=\"Image Index\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:43.645658Z","iopub.execute_input":"2023-12-23T17:09:43.646067Z","iopub.status.idle":"2023-12-23T17:09:43.804872Z","shell.execute_reply.started":"2023-12-23T17:09:43.646035Z","shell.execute_reply":"2023-12-23T17:09:43.803635Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"complete_data_all_info.drop(complete_data_all_info.columns[2:6],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:44.736951Z","iopub.execute_input":"2023-12-23T17:09:44.737405Z","iopub.status.idle":"2023-12-23T17:09:44.760645Z","shell.execute_reply.started":"2023-12-23T17:09:44.737366Z","shell.execute_reply":"2023-12-23T17:09:44.759228Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"complete_data_all_info.drop([\"Unnamed: 11\"],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:46.141858Z","iopub.execute_input":"2023-12-23T17:09:46.142969Z","iopub.status.idle":"2023-12-23T17:09:46.162117Z","shell.execute_reply.started":"2023-12-23T17:09:46.142929Z","shell.execute_reply":"2023-12-23T17:09:46.160816Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"testing_data_info = pd.read_csv(\"/kaggle/input/data/BBox_List_2017.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:47.487084Z","iopub.execute_input":"2023-12-23T17:09:47.487469Z","iopub.status.idle":"2023-12-23T17:09:47.504379Z","shell.execute_reply.started":"2023-12-23T17:09:47.487440Z","shell.execute_reply":"2023-12-23T17:09:47.502962Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"complete_data_all_info = complete_data_all_info.set_index(\"Image Index\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:48.414086Z","iopub.execute_input":"2023-12-23T17:09:48.415048Z","iopub.status.idle":"2023-12-23T17:09:48.444635Z","shell.execute_reply.started":"2023-12-23T17:09:48.415004Z","shell.execute_reply":"2023-12-23T17:09:48.443353Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"testing_data_path_info = complete_data_all_info.loc[testing_data_info[\"Image Index\"]]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:49.534496Z","iopub.execute_input":"2023-12-23T17:09:49.534904Z","iopub.status.idle":"2023-12-23T17:09:49.559658Z","shell.execute_reply.started":"2023-12-23T17:09:49.534874Z","shell.execute_reply":"2023-12-23T17:09:49.558448Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_data_all_info = complete_data_all_info.drop(index=testing_data_path_info.index)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:50.430208Z","iopub.execute_input":"2023-12-23T17:09:50.430593Z","iopub.status.idle":"2023-12-23T17:09:50.464291Z","shell.execute_reply.started":"2023-12-23T17:09:50.430564Z","shell.execute_reply":"2023-12-23T17:09:50.463087Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"testing_data_path_info.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:51.311722Z","iopub.execute_input":"2023-12-23T17:09:51.312133Z","iopub.status.idle":"2023-12-23T17:09:51.318690Z","shell.execute_reply.started":"2023-12-23T17:09:51.312096Z","shell.execute_reply":"2023-12-23T17:09:51.317371Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"testing_data_all_info = testing_data_info.merge(testing_data_path_info,\n                                               on=\"Image Index\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:52.159835Z","iopub.execute_input":"2023-12-23T17:09:52.160277Z","iopub.status.idle":"2023-12-23T17:09:52.171793Z","shell.execute_reply.started":"2023-12-23T17:09:52.160240Z","shell.execute_reply":"2023-12-23T17:09:52.170893Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"testing_data_all_info.drop(labels=testing_data_all_info.columns[6:9],axis=1,\n                          inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:53.088011Z","iopub.execute_input":"2023-12-23T17:09:53.088520Z","iopub.status.idle":"2023-12-23T17:09:53.094966Z","shell.execute_reply.started":"2023-12-23T17:09:53.088480Z","shell.execute_reply":"2023-12-23T17:09:53.093813Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"training_data_all_info[\"Finding Labels\"] = training_data_all_info[\"Finding Labels\"].map(lambda x: x.split(\"|\"))\ntesting_data_all_info[\"Finding Labels\"] = testing_data_all_info[\"Finding Labels\"].map(lambda x: x.split(\"|\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:54.014929Z","iopub.execute_input":"2023-12-23T17:09:54.015936Z","iopub.status.idle":"2023-12-23T17:09:54.295666Z","shell.execute_reply.started":"2023-12-23T17:09:54.015895Z","shell.execute_reply":"2023-12-23T17:09:54.294385Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"merged_list = list()\n\nfor single_list in training_data_all_info[\"Finding Labels\"]:\n    \n    merged_list = merged_list + single_list\n\nunique_diseases = set(merged_list)\nunique_diseases = list(unique_diseases)\nunique_diseases.remove(\"No Finding\")\ndisease2idx = dict(zip(unique_diseases,range(0,len(unique_diseases))))","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:09:55.536579Z","iopub.execute_input":"2023-12-23T17:09:55.538027Z","iopub.status.idle":"2023-12-23T17:10:46.797166Z","shell.execute_reply.started":"2023-12-23T17:09:55.537973Z","shell.execute_reply":"2023-12-23T17:10:46.796032Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def map_diseases(disease_list):\n    \n    all_zeros = np.zeros(len(disease2idx),)\n    \n    for single_disease in disease_list:\n        \n        if single_disease != \"No Finding\":\n            all_zeros[disease2idx[single_disease]] = 1\n        \n    return all_zeros","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:10:49.271563Z","iopub.execute_input":"2023-12-23T17:10:49.271995Z","iopub.status.idle":"2023-12-23T17:10:49.278245Z","shell.execute_reply.started":"2023-12-23T17:10:49.271961Z","shell.execute_reply":"2023-12-23T17:10:49.276963Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n    \n    multi_hot_encoded_Y_train = np.array(list(pool.map(map_diseases,training_data_all_info[\"Finding Labels\"])))\n    multi_hot_encoded_Y_test = np.array(list(pool.map(map_diseases,testing_data_all_info[\"Finding Labels\"])))","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:10:50.742803Z","iopub.execute_input":"2023-12-23T17:10:50.743219Z","iopub.status.idle":"2023-12-23T17:10:57.287454Z","shell.execute_reply.started":"2023-12-23T17:10:50.743181Z","shell.execute_reply":"2023-12-23T17:10:57.286205Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"training_data_all_info.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:10:59.607478Z","iopub.execute_input":"2023-12-23T17:10:59.607905Z","iopub.status.idle":"2023-12-23T17:10:59.616861Z","shell.execute_reply.started":"2023-12-23T17:10:59.607872Z","shell.execute_reply":"2023-12-23T17:10:59.615538Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"training_data_all_info.to_csv(\"training_data.csv\",index=False)\ntesting_data_all_info.to_csv(\"testing_data.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:02.599764Z","iopub.execute_input":"2023-12-23T17:11:02.600154Z","iopub.status.idle":"2023-12-23T17:11:03.787394Z","shell.execute_reply.started":"2023-12-23T17:11:02.600124Z","shell.execute_reply":"2023-12-23T17:11:03.786079Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def custom_training_data_generator(training_data_all_info, multi_hot_encoded_Y_train, mb_size):\n    \n    idx = list(training_data_all_info.index)\n    np.random.shuffle(idx)\n    training_data_all_info = training_data_all_info.iloc[idx]\n    multi_hot_encoded_Y_train = multi_hot_encoded_Y_train[idx]\n    \n    for time_step in range(training_data_all_info.shape[0]//mb_size):\n        \n        X_train_mb = list()\n        \n        for single_img_path in training_data_all_info.iloc[time_step*mb_size:(time_step+1)*mb_size][\"Image Path\"]:\n            \n            resized_single_img =  cv2.resize(np.array(Image.open(single_img_path).convert(\"RGB\")),(1024,1024))\n            X_train_mb.append(resized_single_img)\n            \n        X_train_mb = np.array(X_train_mb)\n        Y_train_mb = multi_hot_encoded_Y_train[time_step*mb_size:(time_step+1)*mb_size]\n        \n        yield X_train_mb, Y_train_mb","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:07.336879Z","iopub.execute_input":"2023-12-23T17:11:07.338115Z","iopub.status.idle":"2023-12-23T17:11:07.346249Z","shell.execute_reply.started":"2023-12-23T17:11:07.338076Z","shell.execute_reply":"2023-12-23T17:11:07.345202Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def custom_testing_data_generator(testing_data_all_info, multi_hot_encoded_Y_test, mb_size):\n    \n    for time_step in range(testing_data_all_info.shape[0]//mb_size):\n        \n        X_test_mb = list()\n        \n        for single_img_path in testing_data_all_info.iloc[time_step*mb_size:(time_step+1)*mb_size][\"Image Path\"]:\n            \n            resized_single_img =  cv2.resize(np.array(Image.open(single_img_path).convert(\"RGB\")),(1024,1024))\n            X_test_mb.append(resized_single_img)\n            \n        X_test_mb = np.array(X_test_mb)\n        Y_test_mb = multi_hot_encoded_Y_test[time_step*mb_size:(time_step+1)*mb_size]\n        \n        bbox_mb = np.array(testing_data_all_info.iloc[time_step*mb_size:(time_step+1)*mb_size,2:6])\n        centroid_mb = bbox_mb[:,0:2] + 0.5*np.concatenate((bbox_mb[:,3],bbox_mb[:,2]),axis=1)\n        \n        img_size_mb = np.array(testing_data_all_info.iloc[time_step*mb_size:(time_step+1)*mb_size,8:10])\n        ordered_img_size_mb = np.concatenate((img_size_mb[:,1],img_size_mb[:,0]),axis=1)\n        rescaled_centroid_mb = centroid_mb * (32/ordered_centroid_mb)\n        \n        yield X_test_mb, Y_test_mb, rescaled_centroid_mb","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:08.984933Z","iopub.execute_input":"2023-12-23T17:11:08.985343Z","iopub.status.idle":"2023-12-23T17:11:08.996693Z","shell.execute_reply.started":"2023-12-23T17:11:08.985307Z","shell.execute_reply":"2023-12-23T17:11:08.995282Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class GlobalLSEPooling2D(tf.keras.layers.Layer):\n    \n    def __init__(self,r_hyper_param):\n        super(GlobalLSEPooling2D, self).__init__()\n        self.r = r_hyper_param\n        \n    def call(self,concatenated_input):\n        x_star_per_channel = GlobalMaxPooling2D(keepdims=True)(concatenated_input)\n        shifted_pix_values = tf.math.exp(self.r*(concatenated_input - x_star_per_channel))\n        avged_output = GlobalAveragePooling2D(keepdims=True)(shifted_pix_values)\n        logged_output = (1/self.r)*tf.math.log(avged_output)\n        layer_output = x_star_per_channel + logged_output\n        \n        return layer_output","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:10.344924Z","iopub.execute_input":"2023-12-23T17:11:10.345306Z","iopub.status.idle":"2023-12-23T17:11:10.353688Z","shell.execute_reply.started":"2023-12-23T17:11:10.345277Z","shell.execute_reply":"2023-12-23T17:11:10.352500Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def chest_x_ray_cnn():\n    \n    input_to_cnn = Input(shape=(1024,1024,3))\n    \n    pretrained_vgg16_conv_base = VGG16(include_top=False,\n                                   input_shape=(1024,1024,3))\n    pretrained_vgg19_conv_base = VGG19(include_top=False,\n                                  input_shape=(1024,1024,3))\n    pretrained_resnet50_conv_base = ResNet50(include_top=False,\n                                        input_shape=(1024,1024,3))\n    pretrained_resnet101_conv_base = ResNet101(include_top=False,\n                                          input_shape=(1024,1024,3))\n\n    pretrained_vgg16_conv_base.trainable = False\n    pretrained_vgg19_conv_base.trainable = False\n    pretrained_resnet50_conv_base.trainable = False\n    pretrained_resnet101_conv_base.trainable = False\n    \n    vgg16_out = pretrained_vgg16_conv_base(input_to_cnn)\n    vgg19_out = pretrained_vgg19_conv_base(input_to_cnn)\n    resnet50_out = pretrained_resnet50_conv_base(input_to_cnn)\n    resnet101_out = pretrained_resnet101_conv_base(input_to_cnn)\n    \n    concatenated_output = Concatenate()([vgg16_out,vgg19_out,\n                                      resnet50_out,resnet101_out])\n    \n    pooled_output = GlobalLSEPooling2D(r_hyper_param=0.9)(concatenated_output)\n    flattened_output = Flatten()(pooled_output)\n    \n    cnn_out = Dense(units=multi_hot_encoded_Y_train.shape[1],\n                    activation=\"sigmoid\")(flattened_output)\n    \n    return Model(inputs=input_to_cnn,outputs=cnn_out)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:11.720743Z","iopub.execute_input":"2023-12-23T17:11:11.721158Z","iopub.status.idle":"2023-12-23T17:11:11.731910Z","shell.execute_reply.started":"2023-12-23T17:11:11.721123Z","shell.execute_reply":"2023-12-23T17:11:11.730795Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"our_custom_cnn = chest_x_ray_cnn()","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:13.320900Z","iopub.execute_input":"2023-12-23T17:11:13.321267Z","iopub.status.idle":"2023-12-23T17:11:42.168860Z","shell.execute_reply.started":"2023-12-23T17:11:13.321237Z","shell.execute_reply":"2023-12-23T17:11:42.167797Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 3s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 4s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 4s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n171446536/171446536 [==============================] - 8s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def weighted_bcel(Y_train_mb,Y_pred_mb):\n    \n    cardinality_p = np.count_nonzero(Y_train_mb)\n    cardinality_n = (Y_train_mb.shape[0]*Y_train_mb.shape[1]) - cardinality_p\n    \n    beta_p = (cardinality_p + cardinality_n + 10**(-7))/(cardinality_p + 10**(-7))\n    beta_n = (cardinality_p + cardinality_n + 10**(-7))/(cardinality_n + 10**(-7))\n    \n    return -tf.reduce_mean(tf.reduce_mean(beta_p*Y_train_mb*tf.math.log(Y_pred_mb) \\\n                          + beta_n*(1-Y_train_mb)*tf.math.log(1-Y_pred_mb),axis=0))","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:54.560540Z","iopub.execute_input":"2023-12-23T17:11:54.560990Z","iopub.status.idle":"2023-12-23T17:11:54.569270Z","shell.execute_reply.started":"2023-12-23T17:11:54.560958Z","shell.execute_reply":"2023-12-23T17:11:54.567972Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def compute_performance_metrics(Y_pred,Y_true,thresh):\n    \n    Y_pred = Y_pred > thresh\n    confusion_matrix = multilabel_confusion_matrix(y_true=Y_true,y_pred=Y_pred)\n    summed_confusion_matrix = np.sum(confusion_matrix,axis=0)\n    \n    tp = summed_confusion_matrix[0,0]\n    tn = summed_confusion_matrix[1,1]\n    fp = summed_confusion_matrix[0,1]\n    fn = summed_confusion_matrix[1,0]\n    \n    accuracy = (tp+tn)/(tp+tn+fp+fn)\n    precision = tp/(tp+fp)\n    recall = tp/(tp+fn)\n    \n    return accuracy,precision,recall    ","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:55.934439Z","iopub.execute_input":"2023-12-23T17:11:55.934861Z","iopub.status.idle":"2023-12-23T17:11:55.943208Z","shell.execute_reply.started":"2023-12-23T17:11:55.934828Z","shell.execute_reply":"2023-12-23T17:11:55.941800Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def predicted_center_pixel_cords(heatmaps):\n    \n    argmax = list()\n    for single_heatmap in heatmaps:\n        \n        heatmap_channels = cv2.split(single_heatmap)\n        argmax_per_heatmap = list()\n    \n        for single_heatmap_channel in heatmap_channels:    \n            single_channel_max_loc = list(np.unravel_index(np.argmax(single_heatmap_channel),single_heatmap_channel.shape))\n            argmax_per_heatmap.append(single_channel_max_loc)\n        \n        argmax.append(np.array(argmax_per_heatmap)/np.array([[7,7]])*224)\n        \n    return np.array(argmax)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:11:59.967218Z","iopub.execute_input":"2023-12-23T17:11:59.967686Z","iopub.status.idle":"2023-12-23T17:11:59.975754Z","shell.execute_reply.started":"2023-12-23T17:11:59.967638Z","shell.execute_reply":"2023-12-23T17:11:59.974395Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"conv_base = Model(inputs=[our_custom_cnn.input],outputs=[our_custom_cnn.layers[5].output])","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:12:03.552456Z","iopub.execute_input":"2023-12-23T17:12:03.552875Z","iopub.status.idle":"2023-12-23T17:12:03.564185Z","shell.execute_reply.started":"2023-12-23T17:12:03.552843Z","shell.execute_reply":"2023-12-23T17:12:03.562662Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.RMSprop()\n\nnum_epochs = 25\ntime_steps = 0\nmb_size = 2\n\nfor epoch in range(num_epochs):\n    for X_train_mb,Y_train_mb in custom_training_data_generator(training_data_all_info,multi_hot_encoded_Y_train,mb_size):\n        \n        with tf.GradientTape() as tape:\n            \n            Y_pred_mb = our_custom_cnn(X_train_mb)\n            w_bcel_value = weighted_bcel(Y_train_mb,Y_pred_mb)\n            \n        gradients = tape.gradient(w_bcel_value,our_custom_cnn.trainable_weights)\n        optimizer.apply_gradients(zip(gradients,our_custom_cnn.trainable_weights))\n        \n        train_acc,train_pre,train_rec = compute_performance_metrics(Y_pred_mb,Y_train_mb,0.5)\n        \n        time_steps += 1\n            \n        print(\"\\n\\nEpoch # {}, Time Step # {}\".format(epoch,time_steps))\n        print(\"WBCEL Value = {}, Training Accuracy = {}, Training Precision = {}, Training Recall = {}\".format(w_bcel_value,\n                                                                                                              train_acc,\n                                                                                                              train_pre,\n                                                                                                              train_rec))\n        conv_base_out = conv_base(X_train_mb).numpy()\n        cls_head_params = our_custom_cnn.layers[-1].weights[0].numpy()\n        \n        heatmaps = np.matmul(conv_base_out,cls_head_params)\n        pred_center_pix_loc = predicted_center_pixel_cords(heatmaps)\n        \n        print(\"Epoch # {}, Time Step # {}, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\".format(epoch,\n                                                                                                                     time_steps))\n        print(pred_center_pix_loc)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T17:12:06.432986Z","iopub.execute_input":"2023-12-23T17:12:06.433449Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\n\nEpoch # 0, Time Step # 1\nWBCEL Value = inf, Training Accuracy = 0.5357142857142857, Training Precision = 0.5357142857142857, Training Recall = 1.0\nEpoch # 0, Time Step # 1, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[320. 320.]\n  [448.   0.]\n  [512.   0.]\n  [ 32.   0.]\n  [ 96. 800.]\n  [992.   0.]\n  [768. 416.]\n  [  0. 736.]\n  [ 64.  32.]\n  [  0.   0.]\n  [384.  64.]\n  [ 64.   0.]\n  [224. 544.]\n  [  0. 288.]]\n\n [[256. 800.]\n  [928.   0.]\n  [320. 320.]\n  [672. 992.]\n  [416.  96.]\n  [  0. 160.]\n  [608. 768.]\n  [352.  32.]\n  [480. 576.]\n  [  0.   0.]\n  [128. 160.]\n  [  0. 416.]\n  [256.   0.]\n  [960.   0.]]]\n\n\nEpoch # 0, Time Step # 2\nWBCEL Value = nan, Training Accuracy = 1.0, Training Precision = 1.0, Training Recall = 1.0\nEpoch # 0, Time Step # 2, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [160. 832.]\n  [  0.   0.]\n  [992. 992.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [960. 992.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]\n\n [[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [ 32. 640.]\n  [  0.   0.]\n  [768. 704.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [640.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]]\n\n\nEpoch # 0, Time Step # 3\nWBCEL Value = nan, Training Accuracy = 1.0, Training Precision = 1.0, Training Recall = 1.0\nEpoch # 0, Time Step # 3, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [448. 288.]\n  [  0.   0.]\n  [  0. 800.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]\n\n [[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [672. 384.]\n  [  0.   0.]\n  [ 32. 128.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]]\n\n\nEpoch # 0, Time Step # 4\nWBCEL Value = nan, Training Accuracy = 0.8214285714285714, Training Precision = 1.0, Training Recall = 0.8214285714285714\nEpoch # 0, Time Step # 4, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [800. 384.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]\n\n [[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [160.  64.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]]\n\n\nEpoch # 0, Time Step # 5\nWBCEL Value = nan, Training Accuracy = 1.0, Training Precision = 1.0, Training Recall = 1.0\nEpoch # 0, Time Step # 5, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [128. 192.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]\n\n [[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [768. 608.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]]\n\n\nEpoch # 0, Time Step # 6\nWBCEL Value = nan, Training Accuracy = 0.9285714285714286, Training Precision = 1.0, Training Recall = 0.9285714285714286\nEpoch # 0, Time Step # 6, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [160.  64.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]\n\n [[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [128. 800.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]]\n\n\nEpoch # 0, Time Step # 7\nWBCEL Value = nan, Training Accuracy = 0.9285714285714286, Training Precision = 1.0, Training Recall = 0.9285714285714286\nEpoch # 0, Time Step # 7, Predicted Location of Each Disease for Chest X-rays in Mini Batch:\n[[[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [160. 192.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]\n\n [[  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [160. 320.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]\n  [  0.   0.]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"\\n\\n\\n\\n\")\n\nthresh_probability = np.arange(start=0.3,stop=0.8,step=0.1)\nfold_size = 123\nK = testing_data_all_info.shape[0]//fold_size\n\nfor fold_idx in range(K):\n    for p_thresh in thresh_probability:\n        \n        cv_data = pd.concat([testing_data_all_info[0:(fold_idx*fold_size)],\n                             testing_data_all_info[(fold_idx+1)*fold_size:]],axis=0)\n        \n        testing_data = testing_data_all_info[(fold_idx*fold_size):(fold_idx+1)*fold_size]\n        \n        multi_hot_encoded_Y_cv = np.concatenate((multi_hot_encoded_Y_test[0:(fold_idx*fold_size)],\n                                                multi_hot_encoded_Y_test[(fold_idx+1)*fold_size:]),\n                                                axis=0)\n        \n        multi_hot_encoded_Y_test = multi_hot_encoded_Y_test[(fold_idx*fold_size):(fold_idx+1)*fold_size]\n        \n        X_cv, Y_cv, rescaled_centroid_cv = custom_testing_data_generator(cv_data,multi_hot_encoded_Y_cv,\n                                                                         cv_data.shape[0])\n        \n        X_test, Y_test, rescaled_centroid_test = custom_testing_data_generator(testing_data,\n                                                                               multi_hot_encoded_Y_test,\n                                                                               testing_data.shape[0])\n        \n        Y_pred_cv = our_custom_cnn(X_cv)\n        cv_acc,cv_pre,cv_rec = compute_performance_metrics(Y_pred_cv,Y_cv,p_thresh)\n        \n        cv_conv_base_out = conv_base(X_cv).numpy()\n        cv_heatmaps = np.matmul(cv_conv_base_out,cls_head_weights)\n        \n        Y_pred_test = our_custom_cnn(X_test)\n        test_acc,test_pre,test_rec = compute_performance_metrics(Y_pred_test,Y_test,p_thresh)\n        \n        test_conv_base_out = conv_base(X_test).numpy()\n        test_heatmaps = np.matmul(test_conv_base_out,cls_head_weights)\n        \n        print(\"Threshold Probability: {}, CV Acc: {}, CV Prec: {}, CV Rec: {}\".format(p_thresh,cv_acc,\n                                                                                            cv_pre,\n                                                                                            cv_rec))\n        \n        print(\"Threshold Probability: {}, Test Acc: {}, Test Prec: {}, Test Rec: {}\".format(p_thresh,\n                                                                                           test_acc,\n                                                                                           test_pre,\n                                                                                           test_rec))","metadata":{},"execution_count":null,"outputs":[]}]}